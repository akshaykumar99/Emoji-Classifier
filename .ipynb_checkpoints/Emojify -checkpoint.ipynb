{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qo_9rMbyCFRp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jAGTo-iGCgJh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/Emojify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2DVrhKClB1Wv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbloA-HoYFcg"
   },
   "source": [
    "Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wKKmv76QB1Wy"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Dataset/emoji_data.csv', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "sr26-CKgB1Wz",
    "outputId": "5a522504-2e2a-40cc-b449-5a70760984b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During the period of falling in love  each tim...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I was involved in a traffic accident .</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I was driving home after several days of ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I lost the person who meant the most to me .</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Label\n",
       "0  During the period of falling in love  each tim...      joy\n",
       "1        When I was involved in a traffic accident .     fear\n",
       "2  When I was driving home after several days of ...    anger\n",
       "3  When I lost the person who meant the most to me .  sadness\n",
       "4  The time I knocked a deer down - the sight of ...  disgust"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1aL2musYB1W6"
   },
   "outputs": [],
   "source": [
    "text = data['Text']\n",
    "label = data['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xGZkUFGYLqU"
   },
   "source": [
    "Unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JY1kXnVkB1W6",
    "outputId": "4d089ea8-6bf3-483d-f21c-07dce0420e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'fear' 'anger' 'sadness' 'disgust' 'shame' 'guilt']\n"
     ]
    }
   ],
   "source": [
    "labels = label.unique()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFDXjmV7YboX"
   },
   "source": [
    "C = Number of unqiue labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t7keuy7AB1W7"
   },
   "outputs": [],
   "source": [
    "C = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6nd1FoEwB1W8"
   },
   "outputs": [],
   "source": [
    "emoji_dict = {\"joy\" : \"ðŸ˜‚\", \"fear\" : \"ðŸ˜±\", \"anger\" : \"ðŸ˜ \", \"sadness\" : \"ðŸ˜¢\", \"disgust\" : \"ðŸ˜’\", \"shame\" : \"ðŸ˜”\", \"guilt\" : \"ðŸ˜³\"}\n",
    "emoji_label = {\"joy\" : 0, \"fear\" : 1, \"anger\" : 2, \"sadness\" : 3, \"disgust\" : 4, \"shame\" : 5, \"guilt\" : 6}\n",
    "no_emoji_dict = {0 : \"ðŸ˜‚\", 1 : \"ðŸ˜±\", 2 : \"ðŸ˜ \", 3 : \"ðŸ˜¢\", 4 : \"ðŸ˜’\", 5 : \"ðŸ˜”\", 6 : \"ðŸ˜³\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Qqy9elvXB1W8"
   },
   "outputs": [],
   "source": [
    "for i in range(len(label)):\n",
    "  label[i] = emoji_label[label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       2\n",
       "3       3\n",
       "4       4\n",
       "       ..\n",
       "7463    4\n",
       "7464    5\n",
       "7465    6\n",
       "7466    0\n",
       "7467    1\n",
       "Name: Label, Length: 7468, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbZzjg9yYmis"
   },
   "source": [
    "Converting labels to one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nAtDngW_B1W8"
   },
   "outputs": [],
   "source": [
    "output_label = convert_to_one_hot(label, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DX4HkRokB1W9"
   },
   "outputs": [],
   "source": [
    "texts = np.array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zLPXqP1nB1W9"
   },
   "outputs": [],
   "source": [
    "count = []\n",
    "for text in texts:\n",
    "    count.append(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6hJIDXV8M2YF"
   },
   "outputs": [],
   "source": [
    "se = pd.Series(np.array(count)).value_counts()\n",
    "# se[70:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7Na1WqiVOvsF"
   },
   "outputs": [],
   "source": [
    "max_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiyrVQ6fY0cg"
   },
   "source": [
    "Splitting data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BhrVJ03FB1W-"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(texts, output_label, test_size = 0.01, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KvR7w5oTigL",
    "outputId": "37dfef4e-bca0-4bc6-cd50-5b6d1f421bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7393,)\n",
      "(75,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mx0jbHyCB1W_",
    "outputId": "99304e98-0d13-4128-934d-411d637f19fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When my new jeans split while I was with the youth group . ðŸ˜”\n",
      "\n",
      "My first real experience with a boy . We were alone . I was quite young and pretty naive and he was pretty crude and real  sort of  macho . It was dark  at night during the summer and we were talking . ðŸ˜”\n",
      "\n",
      "A certain night during initiation . ðŸ˜±\n",
      "\n",
      "When I was a child  I thought that I had to be ashamed when asking and doing certain forbidden things . ðŸ˜”\n",
      "\n",
      "When my brother died . ðŸ˜¢\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(X_train[i], no_emoji_dict[np.argmax(Y_train[i])])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Winod_FjZcpK"
   },
   "source": [
    "read_glove_vecs returns:\n",
    "* word_to_index: dictionary mapping from words to their indices in the vocabulary\n",
    "(400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "* index_to_word: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "* word_to_vec_map: dictionary mapping words to their GloVe vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LP7Wf-tpB1W_"
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('./glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4JPNH_jB1XA",
    "outputId": "a478437f-5dfd-4aea-a2c8-d8aaf6cf86be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzlU29K_ZpVJ"
   },
   "source": [
    "checking whether it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3whwhQ6B1XB",
    "outputId": "89d913fc-06e7-46cf-be50-f64679f7ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of  hello  in the voucabulary is:  176468\n"
     ]
    }
   ],
   "source": [
    "word = 'hello'\n",
    "print('Index of ', word, ' in the voucabulary is: ', word_to_index[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79B_VzebB1XB",
    "outputId": "eb99df35-b879-46b1-c5a5-7ce76f0d9afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word at  176468  index is:  hello\n"
     ]
    }
   ],
   "source": [
    "ind = 176468\n",
    "print('word at ', ind, ' index is: ', index_to_word[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyjFDXhYZv_J"
   },
   "source": [
    "# MODEL\n",
    "Let's build an LSTM model that takes word sequence as input\n",
    "* Emojifier-V2 will continue to use pre-trained word embeddings to represent words.\n",
    "* We will feed word embeddings into an Bidirectional LSTM.\n",
    "* The LSTM will learn to predict the most appropriate emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "baeyXsvoB1XC"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xLGq2PuFB1XD"
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_length):\n",
    "    # number of training examples\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_length))\n",
    "    \n",
    "    # loop over training examples\n",
    "    for i in range(m):  \n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            if j >= 50:\n",
    "                break\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            if(w not in word_to_index):\n",
    "                w = 'unk'\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j = j+1\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmXganDTB1XD",
    "outputId": "6598b8bc-2634-4987-a0ff-fac6abca8148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_check = ['interesting problem' 'yummy' 'the end game']\n",
      "X_check_indices =\n",
      " [[191290. 292794.      0.      0.      0.]\n",
      " [394957.      0.      0.      0.      0.]\n",
      " [357266. 136979. 157049.      0.      0.]]\n"
     ]
    }
   ],
   "source": [
    "X_check = np.array([\"interesting problem\", \"yummy\", \"the end game\"])\n",
    "X_check_indices = sentences_to_indices(X_check,word_to_index, max_length = 5)\n",
    "print(\"X_check =\", X_check)\n",
    "print(\"X_check_indices =\\n\", X_check_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "S2uqu69iB1XE"
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    \n",
    "    # define dimensionality of GloVe word vectors (= 200)\n",
    "    emb_dim = word_to_vec_map[\"hello\"].shape[0]\n",
    "    \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be the word\n",
    "    # vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Keras embedding layer with the correct input and output size and make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None, ))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "NhSNT5XEB1XE"
   },
   "outputs": [],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGZW3zSbB1XF",
    "outputId": "43b09cb7-823a-40cd-b1c3-080da8648fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][2] = -0.49917\n"
     ]
    }
   ],
   "source": [
    "print(\"weights[0][1][2] =\", embedding_layer.get_weights()[0][1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IV6Gfp5SB1XG",
    "outputId": "11e1a410-aa21-4d9a-ddb7-b619da9c9db5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400001, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embedding_layer.get_weights()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "391f4KyPB1XG"
   },
   "outputs": [],
   "source": [
    "def Emojify(input_shape, word_to_vec_map, word_to_index):\n",
    "    \n",
    "    # Define sentence_indices as the input of the graph.\n",
    "    # It should be of shape input_shape and dtype 'int32' (as it contains indices, which are integers).\n",
    "    sentence_indices = Input(input_shape, dtype = 'int32')\n",
    "  \n",
    "    # Create the embedding layer pretrained with GloVe Vectors\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through the embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a batch of sequences.\n",
    "    X = Bidirectional(LSTM(128, return_sequences = True))(embeddings)\n",
    "    \n",
    "    # Add dropout with a probability of 0.4\n",
    "    X = Dropout(0.4)(X)\n",
    "    \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X =  Bidirectional(LSTM(128, return_sequences = False))(X)\n",
    "    \n",
    "    # Add dropout with a probability of 0.4\n",
    "    X =  Dropout(0.4)(X)\n",
    "    \n",
    "    # Propagate X through a Dense layer with 5 units\n",
    "    X = Dense(units = 7)(X)\n",
    "    \n",
    "    # Add a softmax activation\n",
    "    X =  Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Li-GT2YyB1XH",
    "outputId": "2331d973-2f8e-40da-f3ac-992914ebc7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 200)           80000200  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 256)           336896    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 1799      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 80,733,135\n",
      "Trainable params: 732,935\n",
      "Non-trainable params: 80,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify((max_length,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "rxPuACW_B1XH"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "n7cJ1DiTB1XI"
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7P1dzLOgB1XJ",
    "outputId": "17eafd67-e03f-42a1-d96d-cb4b1c668dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 1.6829 - accuracy: 0.3414\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 1.3633 - accuracy: 0.5033\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 1.1715 - accuracy: 0.5807\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 1.0524 - accuracy: 0.6292\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.9600 - accuracy: 0.6650\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.8913 - accuracy: 0.6938\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.8079 - accuracy: 0.7172\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.7281 - accuracy: 0.7456\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 1.1966 - accuracy: 0.5735\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.9150 - accuracy: 0.6781\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.7357 - accuracy: 0.7441\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.6366 - accuracy: 0.7805\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.5732 - accuracy: 0.8029\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.4997 - accuracy: 0.8315\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.4412 - accuracy: 0.8508\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.3996 - accuracy: 0.8666\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.3418 - accuracy: 0.8862\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.3170 - accuracy: 0.8972\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.2582 - accuracy: 0.9126\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.2367 - accuracy: 0.9229\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.2415 - accuracy: 0.9171\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.2072 - accuracy: 0.9313\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.1848 - accuracy: 0.9382\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.1901 - accuracy: 0.9352\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.1411 - accuracy: 0.9517\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.1332 - accuracy: 0.9586\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.1112 - accuracy: 0.9651\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0948 - accuracy: 0.9698\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.1291 - accuracy: 0.9586\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.1269 - accuracy: 0.9586\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0812 - accuracy: 0.9732\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0918 - accuracy: 0.9721\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0823 - accuracy: 0.9765\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0874 - accuracy: 0.9729\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0767 - accuracy: 0.9746\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0800 - accuracy: 0.9754\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0979 - accuracy: 0.9659\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0681 - accuracy: 0.9805\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0649 - accuracy: 0.9794\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.1089 - accuracy: 0.9666\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0568 - accuracy: 0.9816\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0467 - accuracy: 0.9870\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0532 - accuracy: 0.9836\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0717 - accuracy: 0.9788\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0725 - accuracy: 0.9780\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0458 - accuracy: 0.9854\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0550 - accuracy: 0.9820\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0627 - accuracy: 0.9815\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 0.0580 - accuracy: 0.9813\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 3s 14ms/step - loss: 0.0511 - accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f561e04ee10>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEz0K6lcB1XJ",
    "outputId": "3893d7c7-9acd-40bf-878e-84ddae433443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2483 - accuracy: 0.6267\n",
      "Test accuracy =  0.6266666650772095\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_length = max_length)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test)\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXWOyhGsaTth"
   },
   "source": [
    "Try your examples here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhrbIoupGJ8v",
    "outputId": "66132562-60fe-4c3f-e488-34fb6d207104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeling sad more than feeling happy ðŸ˜¢\n"
     ]
    }
   ],
   "source": [
    "x_in = np.array(['feeling sad more than feeling happy'])\n",
    "X_test_indices = sentences_to_indices(x_in, word_to_index, max_length)\n",
    "print(x_in[0] +' '+  no_emoji_dict[np.argmax(model.predict(X_test_indices))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "jZj5Q9gZICUr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Emojify.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
